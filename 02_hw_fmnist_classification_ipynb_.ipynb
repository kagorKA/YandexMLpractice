{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "# Домашнее задание №1\n",
        "## Часть2: Классификация FashionMNIST\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/rads_ai\n",
        "\n",
        "В данном задании вам предстоит решить достаточно простую задачу классификации изображений с помощью сверточных нейронных сетей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision # useful for pics\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V8IGXlqqNCNP"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqxaRocENCNQ"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f-sjVlRfNCNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7c52a9-ddc3-4ff0-81c5-2f432a555299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-14 17:56:27--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-09-14 17:56:27--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-09-14 17:56:27 (110 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q4SuKaGrNCNQ"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cEl107UANCNR"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aYcL28OsgSq8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "76a62e38-a16b-4c85-ce5b-3657ad6224da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 11.3MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 203kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.77MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 24.9MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 3')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Делим трейн на трейн и валидацию"
      ],
      "metadata": {
        "id": "ClVlVnx_N-M0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "train_size = int(0.8 * len(train_fmnist_data))\n",
        "val_size = len(train_fmnist_data) - train_size\n",
        "train_dataset, val_dataset = random_split(train_fmnist_data, [train_size, val_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "Bu4ERfMsZfxC"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для архитектуры модели берем готовый класс Sequentional"
      ],
      "metadata": {
        "id": "KQO4WyRtOGmw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "model_task_1 = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(360, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 10),\n",
        ")\n",
        "model_task_1.to(device)\n",
        "optimizer = torch.optim.Adam(model_task_1.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция потерь"
      ],
      "metadata": {
        "id": "f1NWwXe7OSg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "qGetSm9FXCEo"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тип данных"
      ],
      "metadata": {
        "id": "tX-ao-SuOVrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "default_dtype = torch.float32"
      ],
      "metadata": {
        "id": "A_TgiKk2XNEe"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем функцию обучения модели"
      ],
      "metadata": {
        "id": "PoPS8TZpOYBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "kAf4zDWgYTKT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, val_loader, loss_fn, optimizer, n_epochs=6, device=device):\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "    val_accuracy = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "      ep_train_loss = []\n",
        "      ep_val_loss = []\n",
        "      ep_val_accuracy = []\n",
        "      start_time = time.time()\n",
        "\n",
        "      model.train(True)\n",
        "      for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        preds = model(X_batch)\n",
        "        loss = loss_fn(preds, y_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        ep_train_loss.append(loss.item())\n",
        "\n",
        "      model.train(False)\n",
        "      with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "          X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "          preds = model(X_batch)\n",
        "          loss = loss_fn(preds, y_batch)\n",
        "\n",
        "          ep_val_loss.append(loss.item())\n",
        "          y_pred = preds.max(-1)[1]\n",
        "          ep_val_accuracy.append((y_pred == y_batch).to(default_dtype).mean().item())\n",
        "\n",
        "      print(f\"Epoch {epoch + 1} of {n_epochs} took {time.time() - start_time:.3f}s\")\n",
        "\n",
        "      train_loss.append(np.mean(ep_train_loss))\n",
        "      val_loss.append(np.mean(ep_val_loss))\n",
        "      val_accuracy.append(np.mean(ep_val_accuracy))\n",
        "\n",
        "      print(f\"\\t  training loss: {train_loss[-1]:.6f}\")\n",
        "      print(f\"\\tvalidation loss: {val_loss[-1]:.6f}\")\n",
        "      print(f\"\\tvalidation accuracy: {val_accuracy[-1]:.3f}\")\n",
        "\n",
        "    return train_loss, val_loss, val_accuracy, model"
      ],
      "metadata": {
        "id": "kmZIa7ZV_9Pq"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проводим обучение\n",
        "\n",
        "Лучшие результаты получились со следующими параметрами:\n",
        "\n",
        "\n",
        "\n",
        "*   Архитектура: слой свертки, ReLU, MaxPool, преобразование в вектор, далее чередование линейных преобразований и ReLU (с уменьшением кол-ва признаков)\n",
        "*   Оптимизатор: Adam\n",
        "*   Learning rate: 1e-3\n",
        "*   Количество эпох: 6\n",
        "*   Функция потерь: кросс-энтропия\n",
        "\n"
      ],
      "metadata": {
        "id": "5d5nP226Oi0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, val_loss, val_accuracy, _ = train(model_task_1, train_loader, val_loader, loss_fn, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeNmQtswATvD",
        "outputId": "50c1bebf-25d1-4e02-8107-7f32a8f03204"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of 6 took 11.015s\n",
            "\t  training loss: 0.234178\n",
            "\tvalidation loss: 0.244568\n",
            "\tvalidation accuracy: 0.909\n",
            "Epoch 2 of 6 took 10.875s\n",
            "\t  training loss: 0.217306\n",
            "\tvalidation loss: 0.244186\n",
            "\tvalidation accuracy: 0.910\n",
            "Epoch 3 of 6 took 11.328s\n",
            "\t  training loss: 0.202342\n",
            "\tvalidation loss: 0.250880\n",
            "\tvalidation accuracy: 0.911\n",
            "Epoch 4 of 6 took 11.305s\n",
            "\t  training loss: 0.188993\n",
            "\tvalidation loss: 0.247495\n",
            "\tvalidation accuracy: 0.911\n",
            "Epoch 5 of 6 took 12.349s\n",
            "\t  training loss: 0.177060\n",
            "\tvalidation loss: 0.246756\n",
            "\tvalidation accuracy: 0.915\n",
            "Epoch 6 of 6 took 11.361s\n",
            "\t  training loss: 0.165347\n",
            "\tvalidation loss: 0.271686\n",
            "\tvalidation accuracy: 0.905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xas9SIXDoxvZ"
      },
      "outputs": [],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "_qMQzo1ggSq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11d9230-e2df-4436-c2c4-ed5c933f5a7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJnU14bdnZa_"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95bbada2-a3b8-435e-aba4-ac133ffc1434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.9328\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ba4ff0f-dab9-4650-bbf1-809a648e7319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.8995\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwmTSvDANCNU"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "CUY9qzb9NCNU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b4680c-5c2b-49e7-a933-e43f76dc2bac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_fmnist_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_fmnist_data_dict.npy\"\n",
        "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ0Ci2PrNCNV"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_fmnist_task_1.json` в задачу Separation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}